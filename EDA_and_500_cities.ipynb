{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_E93GSvkZ8d"
      },
      "source": [
        "# EDA: 500 Cities Health Data\n",
        "\n",
        "\n",
        "Raw data download and description: https://www.cdc.gov/500cities/index.htm\n",
        "\n",
        "**Intro:** The 500 Cities project is a collaboration between CDC, the Robert Wood Johnson Foundation, and the CDC Foundation. The purpose of the 500 Cities Project is to provide city- and census tract-level small area estimates for chronic disease risk factors, health outcomes, and clinical preventive service use for the largest 500 cities in the United States. These small area estimates will allow cities and local health departments to better understand the burden and geographic distribution of health-related variables in their jurisdictions, and assist them in planning public health interventions.\n",
        "\n",
        "![picture](https://www.cdc.gov/places/about/500-cities-2016-2019/images/top-500-cities.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prrCXI-w6I7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a01372-8539-4005-ffb7-fd9de412e65b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0fM7sjllGbQ"
      },
      "source": [
        "# Import Modules, Mount Drive, Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blz7Qbt4kXl3"
      },
      "source": [
        "# import modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pylab import * # simpler interface to matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py7xP9-dlQbo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50157622-c655-4b54-d45f-4533cca53097"
      },
      "source": [
        "# copy and paste your code\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g82fv3L2lnKE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "93286a83-f043-48f5-b533-27c6a7ba6e30"
      },
      "source": [
        "# update to your path!\n",
        "# navigate on the left\n",
        "# df = pd.read_csv('/content/drive/My Drive/Fall 2020 Materials/Prep/Module1_PythonDataAnalysis/2_WelcomeToPythonPt2/data/500Cities_clean.csv')\n",
        "df = pd.read_csv('https://drive.google.com/uc?export=download&id=182yTU_RqX9cUcyP3MnUuaFumofNbigmP')\n",
        "\n",
        "df.shape\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StateAbbr</th>\n",
              "      <th>PlaceName</th>\n",
              "      <th>PlaceFIPS</th>\n",
              "      <th>Population2010</th>\n",
              "      <th>ACCESS2_CrudePrev</th>\n",
              "      <th>ARTHRITIS_CrudePrev</th>\n",
              "      <th>BINGE_CrudePrev</th>\n",
              "      <th>BPHIGH_CrudePrev</th>\n",
              "      <th>BPMED_CrudePrev</th>\n",
              "      <th>CANCER_CrudePrev</th>\n",
              "      <th>CASTHMA_CrudePrev</th>\n",
              "      <th>CHD_CrudePrev</th>\n",
              "      <th>CHECKUP_CrudePrev</th>\n",
              "      <th>CHOLSCREEN_CrudePrev</th>\n",
              "      <th>COLON_SCREEN_CrudePrev</th>\n",
              "      <th>COPD_CrudePrev</th>\n",
              "      <th>COREM_CrudePrev</th>\n",
              "      <th>COREW_CrudePrev</th>\n",
              "      <th>CSMOKING_CrudePrev</th>\n",
              "      <th>DENTAL_CrudePrev</th>\n",
              "      <th>DIABETES_CrudePrev</th>\n",
              "      <th>HIGHCHOL_CrudePrev</th>\n",
              "      <th>KIDNEY_CrudePrev</th>\n",
              "      <th>LPA_CrudePrev</th>\n",
              "      <th>MAMMOUSE_CrudePrev</th>\n",
              "      <th>MHLTH_CrudePrev</th>\n",
              "      <th>OBESITY_CrudePrev</th>\n",
              "      <th>PAPTEST_CrudePrev</th>\n",
              "      <th>PHLTH_CrudePrev</th>\n",
              "      <th>SLEEP_CrudePrev</th>\n",
              "      <th>STROKE_CrudePrev</th>\n",
              "      <th>TEETHLOST_CrudePrev</th>\n",
              "      <th>Geolocation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CA</td>\n",
              "      <td>Folsom</td>\n",
              "      <td>624638</td>\n",
              "      <td>72203</td>\n",
              "      <td>7.5</td>\n",
              "      <td>16.9</td>\n",
              "      <td>21.8</td>\n",
              "      <td>25.7</td>\n",
              "      <td>64.8</td>\n",
              "      <td>5.8</td>\n",
              "      <td>8.6</td>\n",
              "      <td>4.1</td>\n",
              "      <td>64.7</td>\n",
              "      <td>78.1</td>\n",
              "      <td>76.6</td>\n",
              "      <td>4.1</td>\n",
              "      <td>37.1</td>\n",
              "      <td>33.3</td>\n",
              "      <td>12.2</td>\n",
              "      <td>74.7</td>\n",
              "      <td>6.7</td>\n",
              "      <td>29.1</td>\n",
              "      <td>2.1</td>\n",
              "      <td>14.3</td>\n",
              "      <td>80.4</td>\n",
              "      <td>9.9</td>\n",
              "      <td>23.8</td>\n",
              "      <td>84.3</td>\n",
              "      <td>8.9</td>\n",
              "      <td>33.9</td>\n",
              "      <td>1.9</td>\n",
              "      <td>6.8</td>\n",
              "      <td>(38.67504943280, -121.147605753)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FL</td>\n",
              "      <td>Largo</td>\n",
              "      <td>1239425</td>\n",
              "      <td>77648</td>\n",
              "      <td>19.6</td>\n",
              "      <td>30.6</td>\n",
              "      <td>16.9</td>\n",
              "      <td>36.1</td>\n",
              "      <td>81.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.9</td>\n",
              "      <td>9.8</td>\n",
              "      <td>77.5</td>\n",
              "      <td>80.2</td>\n",
              "      <td>64.6</td>\n",
              "      <td>10.0</td>\n",
              "      <td>33.7</td>\n",
              "      <td>33.2</td>\n",
              "      <td>20.7</td>\n",
              "      <td>58.6</td>\n",
              "      <td>12.1</td>\n",
              "      <td>39.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>31.0</td>\n",
              "      <td>75.7</td>\n",
              "      <td>13.1</td>\n",
              "      <td>28.3</td>\n",
              "      <td>77.1</td>\n",
              "      <td>15.4</td>\n",
              "      <td>37.7</td>\n",
              "      <td>4.5</td>\n",
              "      <td>18.3</td>\n",
              "      <td>(27.90909077340, -82.7714203383)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CA</td>\n",
              "      <td>Berkeley</td>\n",
              "      <td>606000</td>\n",
              "      <td>112580</td>\n",
              "      <td>7.7</td>\n",
              "      <td>15.1</td>\n",
              "      <td>19.6</td>\n",
              "      <td>20.9</td>\n",
              "      <td>68.2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>8.8</td>\n",
              "      <td>3.7</td>\n",
              "      <td>64.7</td>\n",
              "      <td>70.0</td>\n",
              "      <td>75.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>38.2</td>\n",
              "      <td>36.6</td>\n",
              "      <td>11.2</td>\n",
              "      <td>70.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>27.1</td>\n",
              "      <td>2.1</td>\n",
              "      <td>14.2</td>\n",
              "      <td>81.5</td>\n",
              "      <td>10.9</td>\n",
              "      <td>18.5</td>\n",
              "      <td>83.2</td>\n",
              "      <td>8.2</td>\n",
              "      <td>32.2</td>\n",
              "      <td>1.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>(37.87256787650, -122.274907975)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CA</td>\n",
              "      <td>Napa</td>\n",
              "      <td>650258</td>\n",
              "      <td>76915</td>\n",
              "      <td>12.3</td>\n",
              "      <td>20.7</td>\n",
              "      <td>19.2</td>\n",
              "      <td>28.1</td>\n",
              "      <td>70.2</td>\n",
              "      <td>6.5</td>\n",
              "      <td>8.9</td>\n",
              "      <td>5.8</td>\n",
              "      <td>63.8</td>\n",
              "      <td>75.4</td>\n",
              "      <td>69.3</td>\n",
              "      <td>5.9</td>\n",
              "      <td>37.9</td>\n",
              "      <td>30.3</td>\n",
              "      <td>14.5</td>\n",
              "      <td>70.2</td>\n",
              "      <td>8.9</td>\n",
              "      <td>34.1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>19.8</td>\n",
              "      <td>76.7</td>\n",
              "      <td>12.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>83.9</td>\n",
              "      <td>12.0</td>\n",
              "      <td>32.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>11.2</td>\n",
              "      <td>(38.29804246490, -122.301093331)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FL</td>\n",
              "      <td>Sunrise</td>\n",
              "      <td>1269700</td>\n",
              "      <td>84439</td>\n",
              "      <td>22.8</td>\n",
              "      <td>22.8</td>\n",
              "      <td>16.3</td>\n",
              "      <td>33.3</td>\n",
              "      <td>76.7</td>\n",
              "      <td>6.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>77.7</td>\n",
              "      <td>78.7</td>\n",
              "      <td>59.7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>30.5</td>\n",
              "      <td>26.2</td>\n",
              "      <td>16.5</td>\n",
              "      <td>61.0</td>\n",
              "      <td>12.1</td>\n",
              "      <td>37.1</td>\n",
              "      <td>3.2</td>\n",
              "      <td>29.5</td>\n",
              "      <td>82.5</td>\n",
              "      <td>12.7</td>\n",
              "      <td>28.1</td>\n",
              "      <td>81.3</td>\n",
              "      <td>13.3</td>\n",
              "      <td>38.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>16.2</td>\n",
              "      <td>(26.15468783030, -80.2998411020)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  StateAbbr PlaceName  ...  TEETHLOST_CrudePrev                       Geolocation\n",
              "0        CA    Folsom  ...                  6.8  (38.67504943280, -121.147605753)\n",
              "1        FL     Largo  ...                 18.3  (27.90909077340, -82.7714203383)\n",
              "2        CA  Berkeley  ...                  6.7  (37.87256787650, -122.274907975)\n",
              "3        CA      Napa  ...                 11.2  (38.29804246490, -122.301093331)\n",
              "4        FL   Sunrise  ...                 16.2  (26.15468783030, -80.2998411020)\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA57TuBjLVez"
      },
      "source": [
        "# data dictionary\n",
        "dataDict = pd.read_excel('/content/drive/My Drive/Fall 2020 Materials/Prep/Module1_PythonDataAnalysis/2_WelcomeToPythonPt2/data/Data Dictionary_500 cities.xlsx')\n",
        "# change options to show all rows\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "dataDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMMLZ9Fnlt6i"
      },
      "source": [
        "# Explore the Data\n",
        "We check out the data and see that MOST data is complete, except for one column - `PAPTEST_CrudePrev` - so we will just drop this column for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oMX49vclv-a"
      },
      "source": [
        "# check data types and complete values\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vyD4wCUl-dR"
      },
      "source": [
        "# drop PAPTEST_CrudePrev column\n",
        "df.drop(['PAPTEST_CrudePrev'], axis=1, inplace=True)\n",
        "df.info() # check your work"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VshZR9bglVOZ"
      },
      "source": [
        "Great! No missing values and most data is stored as numeric except for geolocation. Let's see what's going on there..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-9d1ct1ntpi"
      },
      "source": [
        "## Turn Geolocation into two columns - lat and lon\n",
        "A few steps here... first, we remove the non-numeric characters '(' and ')'. Then we split the string into two columns. Then we convert to numeric and check our work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIOIoZ-Xmhn2"
      },
      "source": [
        "# look at the first 10 rows and scroll over - it's a string ('object')\n",
        "df.head(n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R0kLRJin9La"
      },
      "source": [
        "df['Geolocation'] = df['Geolocation'].str.replace('(', '')\n",
        "df['Geolocation'] = df['Geolocation'].str.replace(')', '')\n",
        "df['Geolocation'] = df['Geolocation'].str.replace(',', '')\n",
        "df.head() # check your work"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNj8tlWPQujY"
      },
      "source": [
        "df['Geolocation'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFTELFvvmqbp"
      },
      "source": [
        "# let's make a new column for latitude and longitude (the geographic coords)\n",
        "new = df['Geolocation'].str.split(\" \", n = 1, expand = True)\n",
        "new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N96ZyCQKQzg1"
      },
      "source": [
        "df['lat'] = new[0] # first element of the string\n",
        "df['lon'] = new[1] # second element of the string\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPl6U8GzoqcJ"
      },
      "source": [
        "# check column types\n",
        "df.info()\n",
        "\n",
        "# uh oh! still stored as a string!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwsHoijYnekd"
      },
      "source": [
        "# lat to numeric\n",
        "df['lat'] = pd.to_numeric(df['lat'], errors='coerce')\n",
        "# lon to numeric\n",
        "df['lon'] = pd.to_numeric(df['lon'], errors='coerce')\n",
        "\n",
        "df.info()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfCbLgXHoy7I"
      },
      "source": [
        "# great! now drop the 'Geolocation' column since we don't need it\n",
        "del df['Geolocation']\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYUbLtQbo8CE"
      },
      "source": [
        "# Summary Statistics/Percentiles\n",
        "Since MOST of our data is numeric (except for 'StateAbbr', 'PlaceName'), we can compute numeric summary stats via .describe() from a pandas dataframe.\n",
        "\n",
        "Right away you can compare rates and identify which variables have skewed distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHgYykg8pJfo"
      },
      "source": [
        "# link: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oqIWxhcpb-q"
      },
      "source": [
        "Want more detail? Try some percentiles. With pandas, you can create summary stats right on the dataframe itself.\n",
        "\n",
        "Now you can say things like 20% of towns have 17.9% or less of the population suffering from ARTHRITIS etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyHsQPeRpbY1"
      },
      "source": [
        "# link: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.quantile.html\n",
        "# calculate percentiles for all numeric variables\n",
        "df.quantile(np.arange(0,1.1,0.1)) # every 10%! change to 0.05 for every 5%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEEy_aziqUBx"
      },
      "source": [
        "# GroupBy\n",
        "Let's see how many cities there are per State using groupby our value_counts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ucfawznqZjU"
      },
      "source": [
        "# get a print-out of all the columns\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO7sF-0pqier"
      },
      "source": [
        "Using `value_counts()` from pandas is really nice - this is the count of large cities per State - and we note most of them are in California!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgfeVgwNqcyA"
      },
      "source": [
        "# value counts per 'StateAbbr'\n",
        "df['StateAbbr'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6PFQFl-rQWO"
      },
      "source": [
        "Another way we can do this is with a 'groupby' statement - 'groupby' is nice because you can make a ton of other stats per group. Full customization!\n",
        "\n",
        "Look at how much cool stuff you can do here: https://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gquiut9XrXnn"
      },
      "source": [
        "# for example, let's look at the rates of arthritis for each State\n",
        "tmp = df.groupby(['StateAbbr'])['ARTHRITIS_CrudePrev'].mean().reset_index()\n",
        "tmp # check your work!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w0Jd3-h3WlK"
      },
      "source": [
        "## Sort Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX9D7kV5r6ew"
      },
      "source": [
        "# this is certainly helpful, but maybe we can sort this table\n",
        "# so we can look at the biggest and largest states\n",
        "# link: https://stackoverflow.com/questions/37787698/how-to-sort-pandas-dataframe-from-one-column\n",
        "tmp = tmp.sort_values('ARTHRITIS_CrudePrev', ascending=True)\n",
        "tmp\n",
        "\n",
        "# we see that VT, DC and CA are the best States (lowest rates) for arthritis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBS8XVoGsezs"
      },
      "source": [
        "# how about the highest rates?\n",
        "# link: https://stackoverflow.com/questions/37787698/how-to-sort-pandas-dataframe-from-one-column\n",
        "tmp = tmp.sort_values('ARTHRITIS_CrudePrev', ascending=False)\n",
        "tmp\n",
        "\n",
        "# West Virginia, Ohio and Michigan and Mississippi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmUitVJIsqS4"
      },
      "source": [
        "# Data Enrichment\n",
        "Did you know you can grab .csv files from Github and tables from Wikipedia using pandas? It's awesome.\n",
        "\n",
        "We will grab a list of 'regions and divisions' from Github and we will grab some economic data from Wikipedia then join it all together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urVkRuQ3s1BD"
      },
      "source": [
        "# grab a .csv file from Github\n",
        "# once you go to Github, click through to 'Raw Data'\n",
        "# make sure your link has rawdata at the beggining of the URL\n",
        "\n",
        "# link to github: https://github.com/cphalpert/census-regions/blob/master/us%20census%20bureau%20regions%20and%20divisions.csv\n",
        "# click through to raw data: https://raw.githubusercontent.com/cphalpert/census-regions/master/us%20census%20bureau%20regions%20and%20divisions.csv\n",
        "regionData = pd.read_csv('https://raw.githubusercontent.com/cphalpert/census-regions/master/us%20census%20bureau%20regions%20and%20divisions.csv')\n",
        "regionData.head()\n",
        "\n",
        "# you will be able to join the 'State Code' from regionData and the 'StateAbbr' column from df\n",
        "# and you will have enriched your df data! much more cool columns to do aggregations/tables by."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwBBLEJ7tD_-"
      },
      "source": [
        "# steal some economic data off of Wikipedia\n",
        "\n",
        "# link: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_table.html\n",
        "# link: https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States_by_GDP\n",
        "\n",
        "econData = pd.read_html('https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States_by_GDP')[2]\n",
        "econData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46i_pO7Bxz7K"
      },
      "source": [
        "***SWEET!*** Now we have a ton of geographic and economic data that we can join together.\n",
        "\n",
        "First, we can join the `regionData` to `df`, then we can join `econData` to `df` using the `Statefederal district or territory` column.\n",
        "\n",
        "Be careful of keys - sometimes you need to spend a little time cleaning up text data - part of the joys of being a data analyst or data scientist!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADkZ10F5yVAR"
      },
      "source": [
        "print(df.columns)\n",
        "print(regionData.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgY4mL_WWsuK"
      },
      "source": [
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bizmDdGvWuIG"
      },
      "source": [
        "print(regionData.shape)\n",
        "regionData.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHpEvAV5y1LS"
      },
      "source": [
        "Wow - we are starting to get some really cool features for analysis/exploration..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6yyYPdiyLv4"
      },
      "source": [
        "# join regionData to df\n",
        "# link: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
        "df = df.merge(regionData, left_on='StateAbbr', right_on='State Code')\n",
        "\n",
        "# check your work\n",
        "df.info()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SKREc99y-9P"
      },
      "source": [
        "Keep enriching! Now add the econ data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EPPR4JJzB_E"
      },
      "source": [
        "print(df.columns)\n",
        "print(econData.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj6tCYWsXf19"
      },
      "source": [
        "# this is df data\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2Vk8fOmXlWA"
      },
      "source": [
        "# this is econData\n",
        "print(econData.shape)\n",
        "econData.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qNwp3ABy6Fw"
      },
      "source": [
        "# now we join econData to our newly enriched 'df'\n",
        "# join regionData to df\n",
        "df = df.merge(econData, left_on='State', right_on='Statefederal district or territory')\n",
        "\n",
        "# check your work\n",
        "df.info()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0et0sbVz8dj"
      },
      "source": [
        "## Column Names/ Repetitive Columns\n",
        "The data is complete, but some of our headers are clunky. Let's rename them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cjaXaap0CL0"
      },
      "source": [
        "# first, let's drop any columns that have 100% duplicate information\n",
        "del df['Region_y']\n",
        "\n",
        "# and let's rename 'Region_y' to just 'Region'\n",
        "df.rename(columns={'Region_x':'Region'}, inplace=True) # don't forget this!\n",
        "df.info() # show some good info on non-null values and dtypes\n",
        "df.head() # shows first few rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3scjiWJb1tJb"
      },
      "source": [
        "It looks like `2019[note 1]` could be renamed `2019Population`; `Statefederal district or territory` looks like a repeat of `States`; and columns `Rank`, `2019Population`, `% of Nation` and `GDP` are numbers not objects (strings). So we will convert them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX89kK2T2F6M"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HrI-sKM2bd0"
      },
      "source": [
        "# delete a column\n",
        "del df['Statefederal district or territory']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTrr4Pzi1_Ve"
      },
      "source": [
        "# rename one more column\n",
        "df.rename(columns={'2019[note 1]':'Pop2019'}, inplace=True)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbRPlyD63NAq"
      },
      "source": [
        "## Converting data type: to_numeric()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eKKydrk2gI-"
      },
      "source": [
        "# and convert those few columns to numeric\n",
        "# link: https://stackoverflow.com/questions/36814100/pandas-to-numeric-for-multiple-columns\n",
        "cols = ['Rank',\t'Pop2019',\t'% of Nation',\t'GDP per capita']\n",
        "df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# check your work\n",
        "df.info()\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9raSrRuS3CYK"
      },
      "source": [
        "# All Done!\n",
        "You have made some incredible data for analysis (which you will use in a future optimization model). Now you can make some interesting plots and tables on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5yrNPuT3iHL"
      },
      "source": [
        "# save a copy to your Google Drive\n",
        "\n",
        "# update with a path to your Google Drive\n",
        "df.to_csv('/content/drive/My Drive/Fall 2020 Materials/Prep/Module1_PythonDataAnalysis/2_WelcomeToPythonPt2/data/500Cities_enriched.csv')\n",
        "\n",
        "# you can go into your Google Drive and verify that it's there"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}